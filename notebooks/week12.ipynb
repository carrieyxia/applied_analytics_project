{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd46ec2",
   "metadata": {},
   "source": [
    "# Week 12 - Save and package your model for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "217c77e8-8e86-4a08-bcc3-bdbc00e30c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import dask.dataframe as dd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from joblib import Parallel, delayed\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e954b82d-56b9-4e9a-be20-44a3f85e8b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "train = pd.read_csv('/home/jupyter-fagundem/applied_analytics_project/data/raw/train_final.csv', low_memory=False)\n",
    "validation = pd.read_csv('/home/jupyter-fagundem/applied_analytics_project/data/raw/val_set_final.csv')\n",
    "test = pd.read_csv('/home/jupyter-fagundem/applied_analytics_project/data/raw/test_4_11.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac57007",
   "metadata": {},
   "source": [
    "Changing columns name and dropping columns so both datasets are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b71d270",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.rename(columns={'country': 'country_spain'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9f07315",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['Unnamed: 0'])\n",
    "validation = validation.drop(columns=['Unnamed: 0'])\n",
    "drop = ['join_channel', 'province_name', 'employee_index', 'segment', 'total_products']\n",
    "train = train.drop(columns=drop)\n",
    "validation = validation.drop(columns=drop + ['payroll_acct.1', 'first_contract_date', 'primary_cust', 'last_date_primary', 'deceased'])\n",
    "\n",
    "test = test.drop(columns=['Unnamed: 0'])\n",
    "test = test.drop(columns=drop + ['payroll_acct.1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117dd377-6802-4ff3-82b6-20df3defa130",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Reading into the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec527c7",
   "metadata": {},
   "source": [
    "Setting products we want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "196f8b56-0f83-4403-aa19-545fed66036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = ['savings_acct', 'guarantees', 'current_acct',\n",
    "       'derivada_acct', 'payroll_acct', 'junior_acct', 'mas_particular_acct',\n",
    "       'particular_acct', 'particular_plus_acct', 'short_term_depo',\n",
    "       'medium_term_depo', 'long_term_depo', 'e_acct', 'funds', 'mortgage',\n",
    "       'pension', 'loans', 'taxes', 'credit_card', 'securities', 'home_acct',\n",
    "       'pensions_2', 'direct_debt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64414395-d540-4ccb-9a50-b7eef6385bd8",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6727a634",
   "metadata": {},
   "source": [
    "Defining our Xs and Ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e793f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2 = train.copy()\n",
    "test_2 = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65492e7",
   "metadata": {},
   "source": [
    "# Transformation #2  \n",
    "\n",
    "For tranformation #2 we will add the date column as one of the features. For that, we will calculate the time since purchase using the month we are trying to predict on June 2016. For this transformation to make sense, we will also keep the first transformation, since the time line of purchase matters now, we will keep the duplicate clients' purchases instead of only keeping the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bea3e41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              date  months_since_purchase\n",
      "0       2016-04-01                      2\n",
      "1       2015-07-01                     11\n",
      "2       2016-04-01                      2\n",
      "3       2015-08-01                     10\n",
      "4       2016-03-01                      3\n",
      "...            ...                    ...\n",
      "5757281 2016-05-01                      1\n",
      "5757282 2015-08-01                     10\n",
      "5757283 2015-11-01                      7\n",
      "5757284 2016-05-01                      1\n",
      "5757285 2016-01-01                      5\n",
      "\n",
      "[5757286 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train_2['date'] = pd.to_datetime(train_2['date'], format='%Y-%m-%d')\n",
    "\n",
    "train_2['date'] = train_2['date'].dt.to_period('M').dt.to_timestamp()\n",
    "\n",
    "# Setting our prediction date, June 28, 2016, as the reference date\n",
    "reference_date = pd.to_datetime(\"2016-06-28\")\n",
    "\n",
    "# Calculate time since purchase\n",
    "train_2['months_since_purchase'] = (reference_date.year - train_2['date'].dt.year) * 12 + \\\n",
    "                                   (reference_date.month - train_2['date'].dt.month)\n",
    "\n",
    "print(train_2[['date', 'months_since_purchase']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4287203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              date  months_since_purchase\n",
      "0       2015-06-01                     12\n",
      "1       2016-02-01                      4\n",
      "2       2015-07-01                     11\n",
      "3       2016-03-01                      3\n",
      "4       2016-02-01                      4\n",
      "...            ...                    ...\n",
      "1236739 2016-02-01                      4\n",
      "1236740 2016-02-01                      4\n",
      "1236741 2015-08-01                     10\n",
      "1236742 2016-05-01                      1\n",
      "1236743 2016-04-01                      2\n",
      "\n",
      "[1236744 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Adding feature on test dateased\n",
    "test_2['date'] = pd.to_datetime(test_2['date'], format='%Y-%m-%d')\n",
    "test_2['date'] = test_2['date'].dt.to_period('M').dt.to_timestamp()\n",
    "\n",
    "test_2['months_since_purchase'] = (reference_date.year - test_2['date'].dt.year) * 12 + \\\n",
    "                              (reference_date.month - test_2['date'].dt.month)\n",
    "\n",
    "print(test_2[['date', 'months_since_purchase']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c714336a-6fff-46f5-8608-06a6972f32b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = train_2.drop(['customer_code', 'date'] + products, axis=1)\n",
    "y_train_2 = train_2[products]\n",
    "\n",
    "X_test_2 = test_2.drop(['customer_code', 'date'] + products, axis=1)\n",
    "y_test_2 = test_2[products]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb7b458-f44a-4531-b547-7ef46b39a00f",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d42065c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the best training parameter\n",
    "params = {'C': 10, 'solver': 'liblinear', 'max_iter': 300}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820d7bd5",
   "metadata": {},
   "source": [
    "Database with second transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa9493ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary for storing metrics\n",
    "metrics = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "trained_models = {}\n",
    "\n",
    "# Train and evaluate the model on the 'train_2' dataset\n",
    "for product in products:\n",
    "    clf = LogisticRegression(**params)\n",
    "    \n",
    "    # Train data and labels for each product\n",
    "    y_train_2_product = y_train_2[product].values\n",
    "    y_test_2_product = y_test_2[product].values\n",
    "    \n",
    "    # Train the model\n",
    "    clf.fit(X_train_2, y_train_2_product)\n",
    "\n",
    "    # Sacing the model to the dictionary\n",
    "    trained_models[product] = clf\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_2_pred = clf.predict(X_train_2)\n",
    "    y_test_2_pred = clf.predict(X_test_2)\n",
    "    y_train_2_pred_proba = clf.predict_proba(X_train_2)[:, 1]\n",
    "    y_test_2_pred_proba = clf.predict_proba(X_test_2)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics['train_2']['train'][product] = {\n",
    "        'ROC AUC': roc_auc_score(y_train_2_product, y_train_2_pred_proba),\n",
    "        'F1 Score': f1_score(y_train_2_product, y_train_2_pred),\n",
    "        'Confusion Matrix': confusion_matrix(y_train_2_product, y_train_2_pred)\n",
    "    }\n",
    "    \n",
    "    metrics['train_2']['test'][product] = {\n",
    "        'ROC AUC': roc_auc_score(y_test_2_product, y_test_2_pred_proba),\n",
    "        'F1 Score': f1_score(y_test_2_product, y_test_2_pred),\n",
    "        'Confusion Matrix': confusion_matrix(y_test_2_product, y_test_2_pred)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76395781",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = dict(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76dfe25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluated Model on Dataset: train_2\n",
      "Dataset  Type  Avg ROC AUC  Avg F1 Score\n",
      "train_2 train     0.885926      0.111536\n",
      "train_2  test     0.883623      0.212467\n"
     ]
    }
   ],
   "source": [
    "# Summarize the average metrics across all products\n",
    "summary_data_2 = []\n",
    "for dataset in ['train', 'test']:\n",
    "    avg_roc_auc = np.mean([metrics['train_2'][dataset][p]['ROC AUC'] for p in products])\n",
    "    avg_f1 = np.mean([metrics['train_2'][dataset][p]['F1 Score'] for p in products])\n",
    "    summary_data_2.append(['train_2', dataset, avg_roc_auc, avg_f1])\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary_df_2 = pd.DataFrame(summary_data_2, columns=['Dataset', 'Type', 'Avg ROC AUC', 'Avg F1 Score'])\n",
    "print(\"\\nEvaluated Model on Dataset: train_2\")\n",
    "print(summary_df_2.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cf84e3",
   "metadata": {},
   "source": [
    "## Pickle the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f2d908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('multi_label_metrics.pkl', 'wb') as metrics_file:\n",
    "    pickle.dump(metrics_dict, metrics_file)\n",
    "\n",
    "with open('summary_df.pkl', 'wb') as summary_file:\n",
    "    pickle.dump(summary_df_2, summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b49284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Metrics for Individual Products:\n",
      "{'train_2': defaultdict(<class 'dict'>, {'train': {'savings_acct': {'ROC AUC': 0.8709668741130299, 'F1 Score': 0.0, 'Confusion Matrix': array([[5756696,       0],\n",
      "       [    590,       0]], dtype=int64)}, 'guarantees': {'ROC AUC': 0.9693476237983898, 'F1 Score': 0.0, 'Confusion Matrix': array([[5757167,       0],\n",
      "       [    119,       0]], dtype=int64)}, 'current_acct': {'ROC AUC': 0.7465365034040649, 'F1 Score': 0.789796652125073, 'Confusion Matrix': array([[1154329, 1042230],\n",
      "       [ 556769, 3003958]], dtype=int64)}, 'derivada_acct': {'ROC AUC': 0.8791666642562761, 'F1 Score': 0.0, 'Confusion Matrix': array([[5755008,       0],\n",
      "       [   2278,       0]], dtype=int64)}, 'payroll_acct': {'ROC AUC': 0.8638669338040359, 'F1 Score': 0.0008201085725826688, 'Confusion Matrix': array([[5430634,      85],\n",
      "       [ 326433,     134]], dtype=int64)}, 'junior_acct': {'ROC AUC': 0.9995948324888868, 'F1 Score': 0.8910813874404896, 'Confusion Matrix': array([[5696143,    6417],\n",
      "       [   5594,   49132]], dtype=int64)}, 'mas_particular_acct': {'ROC AUC': 0.8405820430480595, 'F1 Score': 0.0, 'Confusion Matrix': array([[5710122,       0],\n",
      "       [  47164,       0]], dtype=int64)}, 'particular_acct': {'ROC AUC': 0.8835284739148358, 'F1 Score': 0.23261307014645854, 'Confusion Matrix': array([[4845165,  185810],\n",
      "       [ 606263,  120048]], dtype=int64)}, 'particular_plus_acct': {'ROC AUC': 0.8104332199652559, 'F1 Score': 0.0, 'Confusion Matrix': array([[5509710,       0],\n",
      "       [ 247576,       0]], dtype=int64)}, 'short_term_depo': {'ROC AUC': 0.9441958295946022, 'F1 Score': 0.0, 'Confusion Matrix': array([[5749982,       0],\n",
      "       [   7304,       0]], dtype=int64)}, 'medium_term_depo': {'ROC AUC': 0.8947084113434061, 'F1 Score': 0.0, 'Confusion Matrix': array([[5748465,       0],\n",
      "       [   8821,       0]], dtype=int64)}, 'long_term_depo': {'ROC AUC': 0.9258234549675359, 'F1 Score': 0.35640745596918333, 'Confusion Matrix': array([[5464586,   46488],\n",
      "       [ 182741,   63471]], dtype=int64)}, 'e_acct': {'ROC AUC': 0.8589045913055696, 'F1 Score': 0.22031974482151012, 'Confusion Matrix': array([[5203809,   62009],\n",
      "       [ 422949,   68519]], dtype=int64)}, 'funds': {'ROC AUC': 0.9209741654711987, 'F1 Score': 0.003905196701038596, 'Confusion Matrix': array([[5649947,     347],\n",
      "       [ 106782,     210]], dtype=int64)}, 'mortgage': {'ROC AUC': 0.9249286568779911, 'F1 Score': 0.0, 'Confusion Matrix': array([[5722937,       0],\n",
      "       [  34349,       0]], dtype=int64)}, 'pension': {'ROC AUC': 0.9201483103341663, 'F1 Score': 0.004900786705234261, 'Confusion Matrix': array([[5703142,      97],\n",
      "       [  53914,     133]], dtype=int64)}, 'loans': {'ROC AUC': 0.8514761840272447, 'F1 Score': 0.0, 'Confusion Matrix': array([[5743430,       0],\n",
      "       [  13856,       0]], dtype=int64)}, 'taxes': {'ROC AUC': 0.8569855707144118, 'F1 Score': 0.001273281070554751, 'Confusion Matrix': array([[5437058,     211],\n",
      "       [ 319813,     204]], dtype=int64)}, 'credit_card': {'ROC AUC': 0.8881335211333022, 'F1 Score': 0.00633629585627575, 'Confusion Matrix': array([[5495504,     563],\n",
      "       [ 260387,     832]], dtype=int64)}, 'securities': {'ROC AUC': 0.9121396432202691, 'F1 Score': 0.007295732938484318, 'Confusion Matrix': array([[5609248,     521],\n",
      "       [ 146975,     542]], dtype=int64)}, 'home_acct': {'ROC AUC': 0.88738763929116, 'F1 Score': 0.0, 'Confusion Matrix': array([[5734612,       0],\n",
      "       [  22674,       0]], dtype=int64)}, 'pensions_2': {'ROC AUC': 0.8600163079008869, 'F1 Score': 0.0007454154149665965, 'Confusion Matrix': array([[5400571,      91],\n",
      "       [ 356491,     133]], dtype=int64)}, 'direct_debt': {'ROC AUC': 0.8664512533037506, 'F1 Score': 0.04983388284155826, 'Confusion Matrix': array([[4986281,   19766],\n",
      "       [ 731537,   19702]], dtype=int64)}}, 'test': {'savings_acct': {'ROC AUC': 0.8792745067048582, 'F1 Score': 0.0, 'Confusion Matrix': array([[1236601,       0],\n",
      "       [    143,       0]], dtype=int64)}, 'guarantees': {'ROC AUC': 0.9731328180564015, 'F1 Score': 0.0, 'Confusion Matrix': array([[1236659,      50],\n",
      "       [     35,       0]], dtype=int64)}, 'current_acct': {'ROC AUC': 0.7467548232230492, 'F1 Score': 0.7860847306282858, 'Confusion Matrix': array([[262682, 209279],\n",
      "       [134018, 630765]], dtype=int64)}, 'derivada_acct': {'ROC AUC': 0.8503475574802631, 'F1 Score': 0.0, 'Confusion Matrix': array([[1236262,       1],\n",
      "       [    481,       0]], dtype=int64)}, 'payroll_acct': {'ROC AUC': 0.8639926950768051, 'F1 Score': 0.22607812929580165, 'Confusion Matrix': array([[691530, 475548],\n",
      "       [   181,  69485]], dtype=int64)}, 'junior_acct': {'ROC AUC': 0.9996117155228146, 'F1 Score': 0.8859007489816477, 'Confusion Matrix': array([[1224026,    1123],\n",
      "       [   1482,   10113]], dtype=int64)}, 'mas_particular_acct': {'ROC AUC': 0.8407008440316941, 'F1 Score': 0.00019650225977598743, 'Confusion Matrix': array([[1226567,      10],\n",
      "       [  10166,       1]], dtype=int64)}, 'particular_acct': {'ROC AUC': 0.8836132721853001, 'F1 Score': 0.404206014149736, 'Confusion Matrix': array([[1002953,   76878],\n",
      "       [  97695,   59218]], dtype=int64)}, 'particular_plus_acct': {'ROC AUC': 0.8103149884202605, 'F1 Score': 0.0025908194874683186, 'Confusion Matrix': array([[1183548,      95],\n",
      "       [  53032,      69]], dtype=int64)}, 'short_term_depo': {'ROC AUC': 0.94046351444678, 'F1 Score': 0.201705820739189, 'Confusion Matrix': array([[1230735,    4412],\n",
      "       [    923,     674]], dtype=int64)}, 'medium_term_depo': {'ROC AUC': 0.8952822636482807, 'F1 Score': 0.0, 'Confusion Matrix': array([[1234898,       0],\n",
      "       [   1846,       0]], dtype=int64)}, 'long_term_depo': {'ROC AUC': 0.9244951185876386, 'F1 Score': 0.22064701647343335, 'Confusion Matrix': array([[820298, 363742],\n",
      "       [  1063,  51641]], dtype=int64)}, 'e_acct': {'ROC AUC': 0.8572602300572404, 'F1 Score': 0.3646591158786281, 'Confusion Matrix': array([[827410, 304160],\n",
      "       [ 13898,  91276]], dtype=int64)}, 'funds': {'ROC AUC': 0.9191234975964356, 'F1 Score': 0.28292703306803707, 'Confusion Matrix': array([[1195645,   18341],\n",
      "       [  15986,    6772]], dtype=int64)}, 'mortgage': {'ROC AUC': 0.9239200000583363, 'F1 Score': 0.003270200299768361, 'Confusion Matrix': array([[1229417,      77],\n",
      "       [   7238,      12]], dtype=int64)}, 'pension': {'ROC AUC': 0.9202416840890035, 'F1 Score': 0.02748344370860927, 'Confusion Matrix': array([[1224830,     260],\n",
      "       [  11488,     166]], dtype=int64)}, 'loans': {'ROC AUC': 0.8326082444863335, 'F1 Score': 0.0, 'Confusion Matrix': array([[1233790,       0],\n",
      "       [   2954,       0]], dtype=int64)}, 'taxes': {'ROC AUC': 0.8532171804906513, 'F1 Score': 0.29241336663675827, 'Confusion Matrix': array([[955081, 213038],\n",
      "       [ 20392,  48233]], dtype=int64)}, 'credit_card': {'ROC AUC': 0.8864428288797179, 'F1 Score': 0.24285353724199818, 'Confusion Matrix': array([[860799, 320187],\n",
      "       [  3799,  51959]], dtype=int64)}, 'securities': {'ROC AUC': 0.9109758652246804, 'F1 Score': 0.2494479079129942, 'Confusion Matrix': array([[1102383,  102991],\n",
      "       [  12224,   19146]], dtype=int64)}, 'home_acct': {'ROC AUC': 0.8858653151030251, 'F1 Score': 0.0, 'Confusion Matrix': array([[1231825,       0],\n",
      "       [   4919,       0]], dtype=int64)}, 'pensions_2': {'ROC AUC': 0.8600167985952224, 'F1 Score': 0.24403388209314042, 'Confusion Matrix': array([[689671, 470878],\n",
      "       [   166,  76029]], dtype=int64)}, 'direct_debt': {'ROC AUC': 0.8656765654333922, 'F1 Score': 0.4522344904932277, 'Confusion Matrix': array([[688859, 387173],\n",
      "       [   628, 160084]], dtype=int64)}}})}\n",
      "\n",
      " Summary DataFrame:\n",
      "Dataset  Type  Avg ROC AUC  Avg F1 Score\n",
      "train_2 train     0.885926      0.111536\n",
      "train_2  test     0.883623      0.212467\n"
     ]
    }
   ],
   "source": [
    "# Load pickle files\n",
    "with open('multi_label_metrics.pkl', 'rb') as metrics_file:\n",
    "    loaded_metrics = pickle.load(metrics_file)\n",
    "\n",
    "with open('summary_df.pkl', 'rb') as summary_file:\n",
    "    loaded_summary_df = pickle.load(summary_file)\n",
    "\n",
    "# Print results\n",
    "print(\"Loaded Metrics for Individual Products:\")\n",
    "print(loaded_metrics)\n",
    "print(\"\\n Summary DataFrame:\")\n",
    "print(loaded_summary_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
